# Pod 업데이트하고 복구하기

## pod 업데이트

- 컨테이너 버전 업데이트 테스트 파드 배포
  - --record 옵션은 매우 중요한 옵션으로, 배포한 정보의 히스토리를 기록
  - record 옵션으로 기록된 히스토리는 rollout history명령으로 확인 할 수 있음 (kubectl rollout history deployment rollout-nginx)

```bash
[root@m-k8s ~]# kubectl apply -f ~/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record
deployment.apps/rollout-nginx created
```

- rollout-nginx.yaml의 nginx 버전은 nginx:1.15.12

```bash
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rollout-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.15.12
```

- 배포한 파드의 정보를 확인하고 배포된 파드에 속해 있는 nginx 컨테이너 버전을 확인(curl -I 헤더 정보만 보여주는 옵션)

```bash
[root@m-k8s ~]# kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName
NAME                             IP               STATUS    NODE
rollout-nginx-64dd56c7b5-7pcps   172.16.132.1     Running   w3-k8s
rollout-nginx-64dd56c7b5-dj2xl   172.16.103.129   Running   w2-k8s
rollout-nginx-64dd56c7b5-jfxv5   172.16.221.129   Running   w1-k8s
[root@m-k8s ~]# curl -I --silent 172.16.132.1 | grep Server
Server: nginx/1.15.12
```

- set image 명령으로 파드의 nginx 컨테이너 버전을 1.16.0으로 업데이트하고 파드 상태 확인
  - 파드들의 이름과 IP가 중간에 변하는 모습을 볼 수 있음
  - 파드에 속한 nginx 컨테이너를 업데이트하는 가장 쉬운 방법은 파드를 관리하는 replicas의 수를 줄이고 늘려 파드를 새로 생성하는 것

```bash
[root@m-k8s ~]# kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record
deployment.apps/rollout-nginx image updated
[root@m-k8s ~]# kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName
NAME                             IP               STATUS    NODE
rollout-nginx-64dd56c7b5-7pcps   172.16.132.1     Running   w3-k8s
rollout-nginx-64dd56c7b5-dj2xl   172.16.103.129   Running   w2-k8s
rollout-nginx-64dd56c7b5-jfxv5   172.16.221.129   Running   w1-k8s
rollout-nginx-8566d57f75-mw7xv   172.16.132.2     Running   w3-k8s
rollout-nginx-8566d57f75-plwdj   <none>           Pending   w2-k8s
[root@m-k8s ~]# kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName
NAME                             IP               STATUS    NODE
rollout-nginx-8566d57f75-ld5nq   172.16.221.130   Running   w1-k8s
rollout-nginx-8566d57f75-mw7xv   172.16.132.2     Running   w3-k8s
rollout-nginx-8566d57f75-plwdj   172.16.103.130   Running   w2-k8s
[root@m-k8s ~]# curl -I --silent 172.16.221.130 | grep Server
Server: nginx/1.16.0
```

- nginx 컨테이너가 모두 업데이트되면 deployment 상태를 확인하고, rollout  history 명령어로 rollout-nginx에 적용된 명령들을 확인

```bash
[root@m-k8s ~]# kubectl rollout status deployment rollout-nginx
deployment "rollout-nginx" successfully rolled out
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx 
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
2         kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record=true
```



## 업데이트 실패시 파드 복구

- 1.17.2가 아닌 1.17.23으로 입력

```bash
[root@m-k8s ~]# kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record
deployment.apps/rollout-nginx image updated
```

- 상태를 보면 pending(대기중) 상태에서 넘어가지 않음

```bash
[root@m-k8s ~]# kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName
NAME                             IP               STATUS    NODE
rollout-nginx-8566d57f75-ld5nq   172.16.221.130   Running   w1-k8s
rollout-nginx-8566d57f75-mw7xv   172.16.132.2     Running   w3-k8s
rollout-nginx-8566d57f75-plwdj   172.16.103.130   Running   w2-k8s
rollout-nginx-856f4c79c9-slwdd   172.16.103.132   Pending   w2-k8s
```

- rollout status를 실행하면 새로운 replicas는 생성했으나 디플로이먼트를 배포하는 단계에서 대기중으로 더이상 진행되지 않은 걸 확인 할 수 있음

```bash
[root@m-k8s ~]# kubectl rollout status deployment rollout-nginx
Waiting for deployment "rollout-nginx" rollout to finish: 1 out of 3 new replicas have been updated...
```

- 쿠버네티스의 상태를 살펴보는 describe명령어로 문제점을 보면 replicas가 생성되는 단계에서 멈춘 것을 알 수 있음(1.17.23버전의 nginx가 없기 때문)
  - 실수할 가능성이 있기 때문에 rollout을 사용하고 --record를 기록해야함

```bash
[root@m-k8s ~]# kubectl describe deployment rollout-nginx
Name:                   rollout-nginx
Namespace:              default
CreationTimestamp:      Sun, 13 Mar 2022 21:44:32 +0900
Labels:                 <none>
Annotations:            deployment.kubernetes.io/revision: 3
                        kubernetes.io/change-cause: kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record=true
Selector:               app=nginx
Replicas:               3 desired | 1 updated | 4 total | 3 available | 1 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.17.23
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    ReplicaSetUpdated
OldReplicaSets:  rollout-nginx-8566d57f75 (3/3 replicas created)
NewReplicaSet:   rollout-nginx-856f4c79c9 (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  26m   deployment-controller  Scaled up replica set rollout-nginx-64dd56c7b5 to 3
  Normal  ScalingReplicaSet  15m   deployment-controller  Scaled up replica set rollout-nginx-8566d57f75 to 1
  Normal  ScalingReplicaSet  15m   deployment-controller  Scaled down replica set rollout-nginx-64dd56c7b5 to 2
  Normal  ScalingReplicaSet  15m   deployment-controller  Scaled up replica set rollout-nginx-8566d57f75 to 2
  Normal  ScalingReplicaSet  14m   deployment-controller  Scaled down replica set rollout-nginx-64dd56c7b5 to 1
  Normal  ScalingReplicaSet  14m   deployment-controller  Scaled up replica set rollout-nginx-8566d57f75 to 3
  Normal  ScalingReplicaSet  14m   deployment-controller  Scaled down replica set rollout-nginx-64dd56c7b5 to 0
  Normal  ScalingReplicaSet  5m5s  deployment-controller  Scaled up replica set rollout-nginx-856f4c79c9 to 1
```

- 업데이트할 때 사용한 명령어를 확인하고 rollout undo로 마지막 명령어를 취소

```bash
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx 
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
2         kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record=true
3         kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record=true

[root@m-k8s ~]# kubectl rollout undo deployment rollout-nginx
deployment.apps/rollout-nginx rolled back
```

- 파드의 상태를 다시 확인하면 정상적인 상태이고, rollout history로 실행된 명령어를 보면 2번째로 되돌렸기 때문에 2가 삭제되고 가장 최근상태는 version4 가 됨

```bash
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx 
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
3         kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record=true
4         kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record=true
```



## 특정 시점으로 파드 복구

- --to-revision옵션을 사용해서 특정시점으로 돌릴 수 있음. 다시 1.15.12버전으로 돌아간 것을 볼 수 있음

```bash
[root@m-k8s ~]# kubectl rollout undo deployment rollout-nginx --to-revision=1
deployment.apps/rollout-nginx rolled back
[root@m-k8s ~]# kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeNameNAME                             IP               STATUS    NODE
rollout-nginx-64dd56c7b5-88k9q   172.16.132.3     Running   w3-k8s
rollout-nginx-64dd56c7b5-8drwz   172.16.103.133   Running   w2-k8s
rollout-nginx-64dd56c7b5-dn2ll   172.16.221.131   Running   w1-k8s
[root@m-k8s ~]# curl -I --silent 172.16.132.3 | grep Server
Server: nginx/1.15.12
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx 
REVISION  CHANGE-CAUSE
3         kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record=true
4         kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record=true
5         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
```

- 배포된 디플로이먼트 삭제

```bash
[root@m-k8s ~]# kubectl delete -f ~/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml
deployment.apps "rollout-nginx" deleted
[root@m-k8s ~]# kubectl get pods
No resources found in default namespace.
```